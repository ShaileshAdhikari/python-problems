{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rasello-\n",
      "[nltk_data]     ai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/rasello-ai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/rasello-ai/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/rasello-\n",
      "[nltk_data]     ai/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/rasello-\n",
      "[nltk_data]     ai/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re, string\n",
    "\n",
    "nltk.download('stopwords') # Lidt of stopwords\n",
    "nltk.download('punkt') # Punkt Sentence Tokenizer\n",
    "nltk.download('averaged_perceptron_tagger') # tagging words with their parts of speech (POS)\n",
    "nltk.download('wordnet') # lexical database of semantic relations between words \n",
    "nltk.download('omw-1.4') # nltk courpous lazy loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23615"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = 'data/train_set.csv'\n",
    "df = pd.read_csv(train,header=0,encoding='ISO-8859-1')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11348"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset =\"text\",keep = 'first', inplace = True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85389000</td>\n",
       "      <td>pdscpm gb part of panel of chiller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85389000</td>\n",
       "      <td>nm  p economical extended rot hand parts for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85389000</td>\n",
       "      <td>lv ma pd trip unit for cvs parts of circuit br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85389000</td>\n",
       "      <td>lv na p trip unit for cvs switch parts of circ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85389000</td>\n",
       "      <td>lv tmd pd trip unit for cvs parts of circuitbr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  85389000                 pdscpm gb part of panel of chiller\n",
       "1  85389000  nm  p economical extended rot hand parts for c...\n",
       "2  85389000  lv ma pd trip unit for cvs parts of circuit br...\n",
       "3  85389000  lv na p trip unit for cvs switch parts of circ...\n",
       "4  85389000  lv tmd pd trip unit for cvs parts of circuitbr..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "### Simple text cleaning processes: Some of the common text cleaning process involves:\n",
    "* Removing punctuations, special characters, URLs & hashtags\n",
    "* Removing leading, trailing & extra white spaces/tabs\n",
    "* Typos, slangs are corrected, abbreviations are written in their long forms\n",
    "\n",
    "### Stop-word removal\n",
    "* removing words like , ‘i’,’you’,’a’,’the’,’he’,’which’ etc.\n",
    "\n",
    "### Stemming \n",
    "* slicing the end or the beginning of words with the intention of removing affixes(prefix/suffix)\n",
    "* information -> inform or having -> hav\n",
    "\n",
    "### Lemmatization\n",
    "* It is the process of reducing the word to its base form\n",
    "* information -> information or having -> have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() # to lowercase\n",
    "    \n",
    "    text = text.strip()  \n",
    "    text = re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) # removing numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip()) # removing all the puncatation\n",
    "    text = re.sub(r'\\d',' ',text) # removing tariling space\n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    \n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85389000</td>\n",
       "      <td>pdscpm gb part of panel of chiller</td>\n",
       "      <td>pdscpm gb part panel chiller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85389000</td>\n",
       "      <td>nm  p economical extended rot hand parts for c...</td>\n",
       "      <td>nm p economical extend rot hand part circuit b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85389000</td>\n",
       "      <td>lv ma pd trip unit for cvs parts of circuit br...</td>\n",
       "      <td>lv pd trip unit cv part circuit breaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85389000</td>\n",
       "      <td>lv na p trip unit for cvs switch parts of circ...</td>\n",
       "      <td>lv na p trip unit cv switch part circuit breaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85389000</td>\n",
       "      <td>lv tmd pd trip unit for cvs parts of circuitbr...</td>\n",
       "      <td>lv tmd pd trip unit cv part circuitbreakers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "0  85389000                 pdscpm gb part of panel of chiller   \n",
       "1  85389000  nm  p economical extended rot hand parts for c...   \n",
       "2  85389000  lv ma pd trip unit for cvs parts of circuit br...   \n",
       "3  85389000  lv na p trip unit for cvs switch parts of circ...   \n",
       "4  85389000  lv tmd pd trip unit for cvs parts of circuitbr...   \n",
       "\n",
       "                                          clean_text  \n",
       "0                       pdscpm gb part panel chiller  \n",
       "1  nm p economical extend rot hand part circuit b...  \n",
       "2            lv pd trip unit cv part circuit breaker  \n",
       "3   lv na p trip unit cv switch part circuit breaker  \n",
       "4        lv tmd pd trip unit cv part circuitbreakers  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "\n",
    "df['clean_text'] = df['text'].apply(lambda x: finalpreprocess(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few More steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'category_id' with encoded categories \n",
    "df['category_id'] = df['label'].factorize()[0]\n",
    "category_id_df = df[['label', 'category_id']].drop_duplicates()\n",
    "\n",
    "# Dictionaries for future use\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'label']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text_tok']=[nltk.word_tokenize(i) for i in df['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category_id</th>\n",
       "      <th>clean_text_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85389000</td>\n",
       "      <td>pdscpm gb part of panel of chiller</td>\n",
       "      <td>pdscpm gb part panel chiller</td>\n",
       "      <td>0</td>\n",
       "      <td>[pdscpm, gb, part, panel, chiller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85389000</td>\n",
       "      <td>nm  p economical extended rot hand parts for c...</td>\n",
       "      <td>nm p economical extend rot hand part circuit b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nm, p, economical, extend, rot, hand, part, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85389000</td>\n",
       "      <td>lv ma pd trip unit for cvs parts of circuit br...</td>\n",
       "      <td>lv pd trip unit cv part circuit breaker</td>\n",
       "      <td>0</td>\n",
       "      <td>[lv, pd, trip, unit, cv, part, circuit, breaker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85389000</td>\n",
       "      <td>lv na p trip unit for cvs switch parts of circ...</td>\n",
       "      <td>lv na p trip unit cv switch part circuit breaker</td>\n",
       "      <td>0</td>\n",
       "      <td>[lv, na, p, trip, unit, cv, switch, part, circ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85389000</td>\n",
       "      <td>lv tmd pd trip unit for cvs parts of circuitbr...</td>\n",
       "      <td>lv tmd pd trip unit cv part circuitbreakers</td>\n",
       "      <td>0</td>\n",
       "      <td>[lv, tmd, pd, trip, unit, cv, part, circuitbre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "0  85389000                 pdscpm gb part of panel of chiller   \n",
       "1  85389000  nm  p economical extended rot hand parts for c...   \n",
       "2  85389000  lv ma pd trip unit for cvs parts of circuit br...   \n",
       "3  85389000  lv na p trip unit for cvs switch parts of circ...   \n",
       "4  85389000  lv tmd pd trip unit for cvs parts of circuitbr...   \n",
       "\n",
       "                                          clean_text  category_id  \\\n",
       "0                       pdscpm gb part panel chiller            0   \n",
       "1  nm p economical extend rot hand part circuit b...            0   \n",
       "2            lv pd trip unit cv part circuit breaker            0   \n",
       "3   lv na p trip unit cv switch part circuit breaker            0   \n",
       "4        lv tmd pd trip unit cv part circuitbreakers            0   \n",
       "\n",
       "                                      clean_text_tok  \n",
       "0                 [pdscpm, gb, part, panel, chiller]  \n",
       "1  [nm, p, economical, extend, rot, hand, part, c...  \n",
       "2   [lv, pd, trip, unit, cv, part, circuit, breaker]  \n",
       "3  [lv, na, p, trip, unit, cv, switch, part, circ...  \n",
       "4  [lv, tmd, pd, trip, unit, cv, part, circuitbre...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"clean_text\"],\n",
    "                                                    df[\"category_id\"],\n",
    "                                                    test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "1. Count Vectors\n",
    "2. Term Frequency-Inverse Document Frequencies (tf-Idf)\n",
    "\n",
    "### Limitations\n",
    "* It is only useful as a lexical level feature.\n",
    "* Synonymities are neglected.\n",
    "* It doesn't capture semantic.\n",
    "* The highest TF-IDF score may not make sense with the topic of the document, since IDF gives high weight if the DF of a term is low.\n",
    "* It neglects the sequence of the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Count Vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
    "\n",
    "#Tf-Idf\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True) # we will use \"tfidf_vectorizer\" in prediction\n",
    "\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9078, 11690)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "1. with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec\n",
    "# Word2Vec runs on tokenized sentences\n",
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "#building Word2Vec model\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "            return self\n",
    "    def transform(self, X):\n",
    "            return np.array([\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                        or [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "        \n",
    "gen_model = gensim.models.Word2Vec(sentences=df['clean_text_tok'],workers=4,min_count=1)\n",
    "w2v = dict(zip(gen_model.wv.index_to_key, gen_model.wv.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = MeanEmbeddingVectorizer(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text to numerical data using Word2Vec\n",
    "X_train_vectors_w2v = w2v_model.transform(X_train_tok)\n",
    "X_val_vectors_w2v = w2v_model.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9078, 100)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkLearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_bow = svm.SVC(decision_function_shape='ovo',probability=True)\n",
    "svm_model_bow.fit(X_train_vectors_tfidf,y_train)\n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = svm_model_bow.predict(X_test_vectors_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       310\n",
      "           1       0.94      0.95      0.94       307\n",
      "           2       0.86      0.75      0.80       259\n",
      "           3       0.72      0.89      0.79       322\n",
      "           4       0.97      0.87      0.92       270\n",
      "           5       0.91      0.83      0.87       203\n",
      "           6       0.86      0.88      0.87        86\n",
      "           7       0.94      0.71      0.81        21\n",
      "           8       0.79      0.77      0.78       159\n",
      "           9       1.00      0.98      0.99       124\n",
      "          10       0.88      0.75      0.81       107\n",
      "          11       0.99      0.97      0.98       102\n",
      "\n",
      "    accuracy                           0.87      2270\n",
      "   macro avg       0.89      0.86      0.87      2270\n",
      "weighted avg       0.88      0.87      0.87      2270\n",
      "\n",
      "Confusion Matrix:\n",
      " [[281   0   7  14   2   2   3   0   1   0   0   0]\n",
      " [  7 292   0   7   1   0   0   0   0   0   0   0]\n",
      " [ 15   3 195  19   2  13   9   0   2   0   1   0]\n",
      " [ 13   6   1 286   2   2   0   0  11   0   0   1]\n",
      " [  1   6   1  22 234   0   0   0   4   0   2   0]\n",
      " [  5   3  16  10   0 168   0   0   1   0   0   0]\n",
      " [  2   0   7   1   0   0  76   0   0   0   0   0]\n",
      " [  2   0   0   4   0   0   0  15   0   0   0   0]\n",
      " [  5   0   1  21   0   0   0   1 123   0   8   0]\n",
      " [  0   0   0   2   0   0   0   0   0 122   0   0]\n",
      " [  1   1   0  11   0   0   0   0  14   0  80   0]\n",
      " [  1   0   0   2   0   0   0   0   0   0   0  99]]\n",
      "\n",
      "\n",
      "SVM Classification Accuracy 0.8682819383259912\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, y_predict))\n",
    "print('\\n')\n",
    "print('SVM Classification Accuracy',svm_model_bow.score(X_test_vectors_tfidf,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_w2v = svm.SVC(decision_function_shape='ovo',probability=True)\n",
    "svm_model_w2v.fit(X_train_vectors_w2v,y_train)\n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = svm_model_w2v.predict(X_val_vectors_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rasello-ai/PyCharm Projects/python-problems/NLP_classification/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rasello-ai/PyCharm Projects/python-problems/NLP_classification/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rasello-ai/PyCharm Projects/python-problems/NLP_classification/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.72      0.48       310\n",
      "           1       0.84      0.83      0.84       307\n",
      "           2       0.60      0.37      0.46       259\n",
      "           3       0.44      0.46      0.45       322\n",
      "           4       0.72      0.60      0.66       270\n",
      "           5       0.68      0.53      0.60       203\n",
      "           6       0.59      0.43      0.50        86\n",
      "           7       0.00      0.00      0.00        21\n",
      "           8       0.45      0.62      0.53       159\n",
      "           9       1.00      0.81      0.89       124\n",
      "          10       0.00      0.00      0.00       107\n",
      "          11       0.79      0.64      0.71       102\n",
      "\n",
      "    accuracy                           0.57      2270\n",
      "   macro avg       0.54      0.50      0.51      2270\n",
      "weighted avg       0.59      0.57      0.56      2270\n",
      "\n",
      "Confusion Matrix:\n",
      " [[224   3  18  42   9   1   4   0   8   0   0   1]\n",
      " [ 16 256   0  21   3   0   0   0  11   0   0   0]\n",
      " [ 59   5  97  16   8  47  20   0   6   0   0   1]\n",
      " [103  24   3 147  25   1   0   0  17   0   0   2]\n",
      " [ 44   9   0  37 163   0   1   0  14   0   0   2]\n",
      " [ 36   1  41  11   3 108   1   0   2   0   0   0]\n",
      " [ 43   0   2   2   0   2  37   0   0   0   0   0]\n",
      " [ 18   0   0   3   0   0   0   0   0   0   0   0]\n",
      " [ 27   4   0  20   9   0   0   0  99   0   0   0]\n",
      " [  9   0   0   4   0   0   0   0   0 100   0  11]\n",
      " [ 17   1   0  24   4   0   0   0  61   0   0   0]\n",
      " [ 29   0   0   7   1   0   0   0   0   0   0  65]]\n",
      "\n",
      "\n",
      "SVM Classification Accuracy 0.5709251101321586\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, y_predict))\n",
    "print('\\n')\n",
    "print('SVM Classification Accuracy',svm_model_w2v.score(X_val_vectors_w2v,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING test_data FOR NEW PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5894"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'data/test_set.csv'\n",
    "df_test = pd.read_csv(train,header=0,encoding='ISO-8859-1')\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lv tmd pd trip unit for nh parts of circuit br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>module tm analog outputs analog output expansi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  lv tmd pd trip unit for nh parts of circuit br...\n",
       "1  module tm analog outputs analog output expansi..."
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the new dataset\n",
    "df_test['clean_text'] = df_test['text'].apply(lambda x: finalpreprocess(x)) #preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting words to numerical data using tf-idf\n",
    "X_vector=tfidf_vectorizer.transform(df_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting words to numerical data using w2v\n",
    "X_Test_Tok = [nltk.word_tokenize(i) for i in df_test['clean_text'].values]  \n",
    "w2v_x_test = w2v_model.transform(X_Test_Tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the tf-idf model to predict 'target' value for the new dataset \n",
    "Y_pred = svm_model_bow.predict(X_vector)\n",
    "df_test['target_bow'] = Y_pred\n",
    "df_test['label_bow'] = df_test['target_bow'].apply(lambda x: id_to_category[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the w2v model to predict 'target' value for the new dataset \n",
    "Y_pred = svm_model_w2v.predict(w2v_x_test)\n",
    "df_test['target_w2v'] = Y_pred\n",
    "df_test['label_w2v'] = df_test['target_w2v'].apply(lambda x: id_to_category[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>target_bow</th>\n",
       "      <th>label_bow</th>\n",
       "      <th>target_tfidf</th>\n",
       "      <th>label_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lv tmd pd trip unit for nh parts of circuit br...</td>\n",
       "      <td>lv tmd pd trip unit nh part circuit breaker</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>module tm analog outputs analog output expansi...</td>\n",
       "      <td>module tm analog output analog output expansio...</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>command group t iii mechanismt p parts forcir...</td>\n",
       "      <td>command group iii mechanismt p part forcircuit...</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>parts of relayelectrical contact  issu e f xxup</td>\n",
       "      <td>part relayelectrical contact issu e f xxup</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parts for programmable logic controllers  dm  ...</td>\n",
       "      <td>part programmable logic controller dm part plc...</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>gdf latitude  portable computernotebookassyba...</td>\n",
       "      <td>gdf latitude portable computernotebookassybase...</td>\n",
       "      <td>11</td>\n",
       "      <td>84713010</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>cfjx precision  portable computernotebook ass...</td>\n",
       "      <td>cfjx precision portable computernotebook assyb...</td>\n",
       "      <td>11</td>\n",
       "      <td>84713010</td>\n",
       "      <td>0</td>\n",
       "      <td>85389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5891</th>\n",
       "      <td>eguujnnincnnnuas xuup acj note book computer l...</td>\n",
       "      <td>eguujnnincnnnuas xuup acj note book computer l...</td>\n",
       "      <td>11</td>\n",
       "      <td>84713010</td>\n",
       "      <td>11</td>\n",
       "      <td>84713010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5892</th>\n",
       "      <td>egubjnninnnnums wwup note book computer laptop...</td>\n",
       "      <td>egubjnninnnnums wwup note book computer laptop...</td>\n",
       "      <td>11</td>\n",
       "      <td>84713010</td>\n",
       "      <td>11</td>\n",
       "      <td>84713010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5893</th>\n",
       "      <td>lqav hp ids uma iu  g bnbpchp laptophstnnicbis...</td>\n",
       "      <td>lqav hp id uma iu g bnbpchp laptophstnnicbis</td>\n",
       "      <td>11</td>\n",
       "      <td>84713010</td>\n",
       "      <td>11</td>\n",
       "      <td>84713010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5894 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     lv tmd pd trip unit for nh parts of circuit br...   \n",
       "1     module tm analog outputs analog output expansi...   \n",
       "2      command group t iii mechanismt p parts forcir...   \n",
       "3       parts of relayelectrical contact  issu e f xxup   \n",
       "4     parts for programmable logic controllers  dm  ...   \n",
       "...                                                 ...   \n",
       "5889   gdf latitude  portable computernotebookassyba...   \n",
       "5890   cfjx precision  portable computernotebook ass...   \n",
       "5891  eguujnnincnnnuas xuup acj note book computer l...   \n",
       "5892  egubjnninnnnums wwup note book computer laptop...   \n",
       "5893  lqav hp ids uma iu  g bnbpchp laptophstnnicbis...   \n",
       "\n",
       "                                             clean_text  target_bow  \\\n",
       "0           lv tmd pd trip unit nh part circuit breaker           0   \n",
       "1     module tm analog output analog output expansio...           0   \n",
       "2     command group iii mechanismt p part forcircuit...           0   \n",
       "3            part relayelectrical contact issu e f xxup           0   \n",
       "4     part programmable logic controller dm part plc...           0   \n",
       "...                                                 ...         ...   \n",
       "5889  gdf latitude portable computernotebookassybase...          11   \n",
       "5890  cfjx precision portable computernotebook assyb...          11   \n",
       "5891  eguujnnincnnnuas xuup acj note book computer l...          11   \n",
       "5892  egubjnninnnnums wwup note book computer laptop...          11   \n",
       "5893       lqav hp id uma iu g bnbpchp laptophstnnicbis          11   \n",
       "\n",
       "      label_bow  target_tfidf  label_tfidf  \n",
       "0      85389000             0     85389000  \n",
       "1      85389000             0     85389000  \n",
       "2      85389000             0     85389000  \n",
       "3      85389000             0     85389000  \n",
       "4      85389000             0     85389000  \n",
       "...         ...           ...          ...  \n",
       "5889   84713010             0     85389000  \n",
       "5890   84713010             0     85389000  \n",
       "5891   84713010            11     84713010  \n",
       "5892   84713010            11     84713010  \n",
       "5893   84713010            11     84713010  \n",
       "\n",
       "[5894 rows x 6 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     735\n",
       "2     698\n",
       "1     641\n",
       "3     618\n",
       "4     484\n",
       "8     468\n",
       "5     467\n",
       "7     395\n",
       "9     384\n",
       "6     358\n",
       "11    328\n",
       "10    318\n",
       "Name: target_bow, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_test['target_bow']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def batch_generator_shuffle(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    np.random.shuffle(index)\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].toarray()\n",
    "        y_batch = y_data[y_data.index[index_batch]]\n",
    "        counter += 1\n",
    "        yield tf.expand_dims(X_batch, 0), X_batch\n",
    "        if (counter > number_of_batches):\n",
    "            np.random.shuffle(index)\n",
    "            counter=0\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu',input_shape=(32,11666)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit_generator(generator=batch_generator_shuffle(X_train_vectors_tfidf, y_train, 32),\n",
    "                    epochs=5, \n",
    "                    validation_data=(X_test_vectors_tfidf, y_test),\n",
    "                    steps_per_epoch=X_train_vectors_tfidf.shape[0]//32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}